{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple Matrix Factorization Collaborative Filtering for Drug Repositioning on Cell Lines\n",
    "\n",
    "The discovery of new biological interactions, such as interactions between drugs and cell lines, can improve the way drugs are developed. Recently, there has been important interest for predicting interactions between drugs and targets using recommender systems; and more specifically, using recommender systems to predict drug activity on cellular lines. In this work, we present a simple and straightforward approach for the discovery of interactions between drugs and cellular lines using collaborative filtering. We represent cellular lines by their drug affinity profile, and correspondingly, represent drugs by their cell line affinity profile in a single interaction matrix. Using simple matrix factorization, we predicted previously unknown values, minimizing the regularized squared error. We build a comprehensive dataset with information from the ChEMBL database. Our dataset comprises 300,000+ molecules, 1,200+ cellular lines, and 3,000,000+ reported activities. We have been able to successfully predict drug activity, and evaluate the performance of our model via utility, achieving an Area Under ROC Curve (AUROC) of near 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should check that compounds and cells share IDs among versions\n",
    "\n",
    "We load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cell_df = pd.read_csv(filepath_or_buffer='data/cell_summary.csv', index_col=0)\n",
    "comp_df = pd.read_csv(filepath_or_buffer='data/comp_summary.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the IDs are the same for cellular lines and compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [cell_name, id_24, id_25, id_26, id_27]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [cell_name, id_24, id_25, id_26, id_27]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [cell_name, id_24, id_25, id_26, id_27]\n",
      "Index: []\n",
      "                                    smiles         pref_name    id_24  \\\n",
      "35                     COC(=O)C1=CCCN(C)C1         ARECOLINE     1022   \n",
      "37         COc1cc(Cc2cnc(N)nc2N)cc(OC)c1OC      TRIMETHOPRIM     1216   \n",
      "39     Nc1nc(N)c2cc(Sc3ccc4ccccc4c3)ccc2n1               NaN     1312   \n",
      "62                      CCCC(CCC)C(=O)[O-]  VALPROATE SODIUM     1991   \n",
      "74                  NCCc1c[nH]c2ccc(O)cc12         SEROTONIN     2214   \n",
      "...                                    ...               ...      ...   \n",
      "37798                  CCCCCCn1cc[n+](C)c1               NaN  1672762   \n",
      "38361           NCCCNCCCNC1CCCCCCCCCCCCCC1               NaN  1745509   \n",
      "46873   CNCc1cc(OCc2ccc3ccc(N)nc3c2)ccc1Cl               NaN  2051958   \n",
      "47483               CSc1c(C)c(SC)n2ccncc12               NaN  2082834   \n",
      "47716           CCCCCC[P+](CCCC)(CCCC)CCCC               NaN  2092081   \n",
      "\n",
      "         id_25    id_26    id_27  scomp_id  \n",
      "35        1022   522563   522563        35  \n",
      "37        1216   854495   854495        37  \n",
      "39        1312   831053   831053        39  \n",
      "62        1991     1991  1377883        62  \n",
      "74        2214   549378   549378        74  \n",
      "...        ...      ...      ...       ...  \n",
      "37798  1672762  2058720  2058720     37798  \n",
      "38361  1745509  2205188  2205188     38361  \n",
      "46873  2051958  2052333  2052333     46873  \n",
      "47483  2082834  2082845  2082845     47483  \n",
      "47716  2092081  2092082  2092082     47716  \n",
      "\n",
      "[263 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cell_df[cell_df['id_24'] != cell_df['id_25']])\n",
    "print(cell_df[cell_df['id_24'] != cell_df['id_26']])\n",
    "print(cell_df[cell_df['id_24'] != cell_df['id_27']])\n",
    "# IDs for Cellular lines are all the same\n",
    "\n",
    "print(comp_df[comp_df['id_24'] != comp_df['id_27']])\n",
    "# IDs for Compounds differ\n",
    "# So, we create a new column scomp_id\n",
    "comp_df['scomp_id'] = comp_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to update activity dataframes in order to standardize the compound IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dmii\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "activity_24 = pd.read_csv(filepath_or_buffer='data/summary_24.csv', index_col=0)\n",
    "activity_25 = pd.read_csv(filepath_or_buffer='data/summary_25.csv', index_col=0)\n",
    "activity_26 = pd.read_csv(filepath_or_buffer='data/summary_26.csv', index_col=0)\n",
    "activity_27 = pd.read_csv(filepath_or_buffer='data/summary_27.csv', index_col=0)\n",
    "\n",
    "activity_24 = pd.merge(left=activity_24, right=comp_df, left_on='comp_id', right_on='id_24')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity', 'comp_id']]\n",
    "activity_25 = pd.merge(left=activity_25, right=comp_df, left_on='comp_id', right_on='id_25')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity', 'comp_id']]\n",
    "activity_26 = pd.merge(left=activity_26, right=comp_df, left_on='comp_id', right_on='id_26')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity', 'comp_id']]\n",
    "activity_27 = pd.merge(left=activity_27, right=comp_df, left_on='comp_id', right_on='id_27')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity', 'comp_id']]\n",
    "\n",
    "activity_24.to_csv(path_or_buf='data/activity_24.csv', header=True, index=True)\n",
    "activity_25.to_csv(path_or_buf='data/activity_25.csv', header=True, index=True)\n",
    "activity_26.to_csv(path_or_buf='data/activity_26.csv', header=True, index=True)\n",
    "activity_27.to_csv(path_or_buf='data/activity_27.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the differences between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The difference dataset diff should be calculated for the pair train-test\n",
    "activity_24 = activity_24.drop_duplicates(keep=\"first\")\n",
    "activity_27 = activity_27.drop_duplicates(keep=\"first\")\n",
    "\n",
    "# diff = pd.concat([activity_26,activity_27]).drop_duplicates(keep=False).reset_index()\n",
    "diff = activity_27.merge(activity_24, how = 'outer',indicator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start with the Recommender System.\n",
    "We are using `scikit-surprise`, and following documentation from:\n",
    "https://surprise.readthedocs.io/en/stable/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cell_df = pd.read_csv(filepath_or_buffer='data/cell_summary.csv', index_col=0)\n",
    "comp_df = pd.read_csv(filepath_or_buffer='data/comp_summary_nan.csv', index_col=0)\n",
    "\n",
    "comp_df['scomp_id'] = comp_df.index\n",
    "\n",
    "activity_24 = pd.read_csv(filepath_or_buffer='data/summary_24.csv', index_col=0)\n",
    "activity_25 = pd.read_csv(filepath_or_buffer='data/summary_25.csv', index_col=0)\n",
    "activity_26 = pd.read_csv(filepath_or_buffer='data/summary_26.csv', index_col=0)\n",
    "activity_27 = pd.read_csv(filepath_or_buffer='data/summary_27.csv', index_col=0)\n",
    "\n",
    "activity_24 = pd.merge(left=activity_24, right=comp_df, left_on='comp_id', right_on='id_24', how='left')[['cell_id',\n",
    "                                                                                            'scomp_id', 'activity']]\n",
    "activity_25 = pd.merge(left=activity_25, right=comp_df, left_on='comp_id', right_on='id_25')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity']]\n",
    "activity_26 = pd.merge(left=activity_26, right=comp_df, left_on='comp_id', right_on='id_26')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity']]\n",
    "activity_27 = pd.merge(left=activity_27, right=comp_df, left_on='comp_id', right_on='id_27')[['cell_id', 'scomp_id',\n",
    "                                                                                              'activity']]\n",
    "\n",
    "activity_24.loc[activity_24['activity'] == 0, 'activity'] = -1\n",
    "activity_25.loc[activity_25['activity'] == 0, 'activity'] = -1\n",
    "activity_26.loc[activity_26['activity'] == 0, 'activity'] = -1\n",
    "activity_27.loc[activity_27['activity'] == 0, 'activity'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next program is to GridSearch the best algorithm and then compare training performance with test dataset v27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search...\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "reader = Reader(rating_scale=(-1, 1))\n",
    "data = Dataset.load_from_df(activity_24[['cell_id', 'scomp_id', 'activity']], reader)\n",
    "\n",
    "# Select your best algo with grid search.\n",
    "print('Grid Search...')\n",
    "\n",
    "param_grid = {'n_factors': [10, 50, 100, 200, 300, 400, 500, 1000, 2000, 5000], #Best is: 10\n",
    "              'n_epochs': [10, 50, 100, 200, 300, 400, 500], #Best is: 300\n",
    "              'lr_all': [0.001, 0.002, 0.005, 0.01, 0.02, 0.05], #Best is .002\n",
    "              'reg_all': [0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0], #Best is .1\n",
    "              'biased' : [True, False] #Best is True\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse', 'mae'], cv=10, n_jobs=-1, refit=True)\n",
    "grid_search.fit(data)\n",
    "\n",
    "algo = grid_search.best_estimator['rmse']\n",
    "print(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "print('Biased accuracy on v24,', end='   ')\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "data_diff = Dataset.load_from_df(diff[['cell_id', 'scomp_id', 'activity']], reader)\n",
    "testset = data_diff.construct_testset(data_diff.raw_ratings)  # testset is diff\n",
    "predictions = algo.test(testset)\n",
    "print('Unbiased accuracy on diff,', end=' ')\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# v24v27 Unbiased accuracy on diff, RMSE: 0.7838\n",
    "# v24v25 Unbiased accuracy on diff, RMSE: 0.7751\n",
    "# v24v25 Unbiased accuracy on diff, RMSE: 0.7398\n",
    "# v26v27 Unbiased accuracy on diff, RMSE: 0.6843"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we calculate and plot ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r = list()\n",
    "est = list()\n",
    "for p in predictions:\n",
    "    r.append(p.r_ui)\n",
    "    est.append(p.est)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(r, est)\n",
    "plt.show()\n",
    "plt.savefig('img/surprise_gridcv_v24v27.png')\n",
    "plt.close()\n",
    "\n",
    "#ROC Curve\n",
    "from sklearn import metrics\n",
    "y = pd.DataFrame({'r':r, 'est':est})\n",
    "\n",
    "y.loc[y['r'] == -1, 'r'] = 0\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true=y['r'], y_score=y['est'])\n",
    "auc = metrics.roc_auc_score(y_true=y['r'], y_score=y['est'])\n",
    "print('AUC: %.9f' % auc)\n",
    "# v24v27 AUC: 0.869446782\n",
    "# v24v26 AUC: 0.874650992\n",
    "# v24v25 AUC: 0.896068396\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('img/surprise_roc_v24v27.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}